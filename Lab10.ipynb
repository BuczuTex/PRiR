{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPE89/lClZlWC/9VyjfNHUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BuczuTex/PRiR/blob/master/Lab10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi6K3SPG7bUo"
      },
      "source": [
        "# Zadanie 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5Zh_F7d7j8Z"
      },
      "source": [
        "##Całkowanie numeryczne za pomocą metody prostokątów przy użyciu f(x) = x^2+2 oraz n = 300."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh5XwE2G93CD",
        "outputId": "32960ae2-8f92-49fd-fad0-7fd2c24545dd"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import time\r\n",
        "\r\n",
        "def f(x):\r\n",
        "  return x*x+2\r\n",
        "\r\n",
        "\r\n",
        "def calka_prostokat(funkcja, a, b, n):\r\n",
        "  a = tf.constant(a, dtype = tf.float64)\r\n",
        "  b = tf.constant(b, dtype = tf.float64)\r\n",
        "  dx = (b - a)/n\r\n",
        "  wynik = 0\r\n",
        "  for i in range(1, n + 1):\r\n",
        "    wynik = wynik + funkcja(a + i * dx)\r\n",
        "  wynik *= dx\r\n",
        "  return wynik\r\n",
        "\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "wynik_calkowanie = calka_prostokat(tf.function(func = f), 1, 2, 300)\r\n",
        "print(f\"Wynik całkowania za pomocą metody prostokątów: {wynik_calkowanie} przy czasie {time.time() - start_time}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wynik całkowania za pomocą metody prostokątów: 4.3383351851851835 przy czasie 0.16867780685424805s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bahEck9LJT33"
      },
      "source": [
        "Wynik całkowania wynosi 4.3383351851851835.<br>\r\n",
        "Czas bez użycia GPU wynosi 0.2563135623931885s<br>\r\n",
        "Czas z użyciem GPU wynosi 0.16867780685424805s <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X0mRix0KXBl"
      },
      "source": [
        "##Całkowanie numeryczne za pomocą metody trapezów przy użyciu f(x) = x^2+2 oraz n = 300."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smcX0KqoV8hS",
        "outputId": "e75f7817-c269-43a2-fa8b-797a2000dcc7"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import time\r\n",
        "\r\n",
        "\r\n",
        "def f(x):\r\n",
        "  return x*x+2\r\n",
        "\r\n",
        "\r\n",
        "def calka_trapez(funkcja, a, b, n):\r\n",
        "  a = tf.constant(a, dtype = tf.float64)\r\n",
        "  b = tf.constant(b, dtype = tf.float64)\r\n",
        "  dx = (b - a)/n\r\n",
        "  wynik = funkcja(a)/2 + funkcja(b)/2\r\n",
        "  for i in range(1, n):\r\n",
        "    wynik = wynik + funkcja(a + i*dx)\r\n",
        "  wynik *= dx\r\n",
        "  return wynik\r\n",
        "\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "wynik_calkowanie = calka_trapez(tf.function(func = f), 1, 2, 300)\r\n",
        "print(f\"Wynik całkowania za pomocą metody prostokątów: {wynik_calkowanie} przy czasie {time.time() - start_time}s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wynik całkowania za pomocą metody prostokątów: 4.333335185185184 przy czasie 0.1616497039794922s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0l5pcG4YQba"
      },
      "source": [
        "Wynik całkowania wynosi 4.333335185185184. <br>\r\n",
        "Czas bez użycia GPU wynosi 0.18331170082092285s. <br>\r\n",
        "Czas z użyciem GPU wynosi 0.1616497039794922s. <br>\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxOqBmUnYsXa"
      },
      "source": [
        "##Całkowanie numeryczne za pomocą metody Simpsona przy użyciu f(x) = x^2+2 oraz n = 300."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKbv9zk7Y4lR",
        "outputId": "1c00b296-a4d3-49aa-dca3-f8ca5af9facd"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import time\r\n",
        "\r\n",
        "def f(x):\r\n",
        "  return x*x+2\r\n",
        "\r\n",
        "\r\n",
        "def calka_Simpson(funkcja, a, b, n):\r\n",
        "  a = tf.constant(a, dtype = tf.float64)\r\n",
        "  b = tf.constant(b, dtype = tf.float64)\r\n",
        "  dx = 0\r\n",
        "  wynik = funkcja(a) + funkcja(b)\r\n",
        "  x0 = 0\r\n",
        "  x1 = 0\r\n",
        "  for i in range(0, n):\r\n",
        "    x0 = a + (i * (b - a))/n\r\n",
        "    x1 = a + ((i + 1) * (b - a))/n\r\n",
        "    wynik += 4 * funkcja((x1 + x0)/2)\r\n",
        "    if i == 0:\r\n",
        "      dx = (x1 - x0) / 2\r\n",
        "  for i in range(1, n):\r\n",
        "    wynik += 2 * funkcja(a + (i * (b - a))/n)\r\n",
        "  wynik *= dx/3\r\n",
        "  return wynik\r\n",
        "\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "wynik_calkowanie = calka_Simpson(tf.function(func = f), 1, 2, 300)\r\n",
        "print(f\"Wynik całkowania za pomocą metody Simpsona: {wynik_calkowanie} przy czasie {time.time() - start_time}s\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wynik całkowania za pomocą metody Simpsona: 4.333333333333437 przy czasie 6.102625846862793s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pesKL4NDcPKy"
      },
      "source": [
        "Wynik całkowania wynosi 4.333333333333437. <br>\r\n",
        "Czas bez użycia GPU wynosi 0.35242676734924316s. <br>\r\n",
        "Czas z użyciem GPU wynosi 0.39826393127441406s. <br>\r\n",
        "W tym przypadku, użycie GPU skutkuje wydłużonym czasem kompilacji. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKhMD8L7eIX8"
      },
      "source": [
        "# Zadanie 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiRjSvongAlj"
      },
      "source": [
        "## Interpolacja funkcji 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VI4eIuZgSpT",
        "outputId": "42e95ed1-1e3a-47de-8c03-71ddd2ea9699"
      },
      "source": [
        "import numpy as np\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import os\r\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "def funkcja(x):\r\n",
        "  return (x-2)*(x+1)*(x-4)\r\n",
        "xs = np.arange(-100.0, 100.00025, 0.00025, dtype = float)\r\n",
        "ys = []\r\n",
        "#Przykłady dla sieci neuronowej do uczenia\r\n",
        "for x in xs:\r\n",
        "  ys.append(funkcja(x))\r\n",
        "ys = np.array(ys, dtype = float)\r\n",
        "#Utworzenie sieci neuronowej\r\n",
        "model = tf.keras.Sequential([\r\n",
        "                             keras.layers.Dense(units = 1, input_shape = [1]),\r\n",
        "                             keras.layers.Dense(units = 1000, activation = \"relu\", input_shape = [1]),\r\n",
        "                             keras.layers.Dense(units = 1000, activation = \"relu\", input_shape = [1]),\r\n",
        "                             keras.layers.Dense(units = 1000, activation = \"relu\", input_shape = [1]),\r\n",
        "                             keras.layers.Dense(units = 1000, activation = \"relu\", input_shape = [1]),\r\n",
        "                             keras.layers.Dense(units = 1000, activation = \"relu\", input_shape = [1]),\r\n",
        "                             keras.layers.Dense(units = 1)\r\n",
        "                             ])\r\n",
        "#Wyznaczenie funkcji optymalizatora i funkcji straty\r\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_logarithmic_error')\r\n",
        "#Trenowanie sieci neuronowej\r\n",
        "model.fit(xs, ys, epochs = 100, steps_per_epoch = 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 4.2651\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.3036\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0151\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0061\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 8.9789e-04\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 8.9230e-04\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 8.4342e-04\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 7.5565e-04\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 4.7010e-04\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 7.3698e-04\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 6.9710e-04\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 4.9833e-04\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 5.9071e-04\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 5.1910e-04\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 5.8872e-04\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 4.5760e-04\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 5.5442e-04\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 4.7820e-04\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 4.9631e-04\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 4.5301e-04\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 5.6526e-04\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 3.7658e-04\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.3192e-04\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 4.6022e-04\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 3.3695e-04\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.6157e-04\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 3.4557e-04\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.7897e-04\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.5057e-04\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.5072e-04\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 3.3313e-04\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.2291e-04\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.5687e-04\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.9772e-04\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.7605e-04\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.2321e-04\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.1348e-04\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.5856e-04\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.3742e-04\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.4293e-04\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.9807e-04\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.1295e-04\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.0951e-04\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.9147e-04\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.2363e-04\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.9320e-04\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.6686e-04\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.0487e-04\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.2693e-04\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.6641e-04\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.0857e-04\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.9856e-04\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.0834e-04\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.8105e-04\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.3286e-04\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.3842e-04\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.7494e-04\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.4162e-04\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.8981e-04\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.1892e-04\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.0750e-04\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 2.0300e-04\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.4884e-04\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.2399e-04\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.1375e-04\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.5376e-04\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.5859e-04\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.7985e-04\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.2553e-04\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.4086e-04\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.2396e-04\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.1519e-04\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.1687e-04\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.1465e-04\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.2754e-04\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.0827e-04\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.1904e-04\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.3966e-04\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.1471e-04\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.0502e-04\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.3103e-04\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 9.1244e-05\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.5058e-04\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 9.0589e-05\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.1121e-04\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.1667e-04\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 1.3827e-04\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 7.1600e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5d025ab2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9szUBY207ByD"
      },
      "source": [
        "Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbgOdeP24IOm",
        "outputId": "db55a343-5764-455f-fd54-700f9835328a"
      },
      "source": [
        "x = input(\"Proszę podać x: \")\r\n",
        "print(f\"Wynik dla danego x:\", model.predict([float(x)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proszę podać x: 12\n",
            "Wynik dla danego x: [[1037.1472]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxu4v1SS8X6E"
      },
      "source": [
        "##Interpolacja funkcji 2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycTYHoCY8ekE",
        "outputId": "718eaf4b-74a8-461c-ff59-2b4f59a534db"
      },
      "source": [
        "from math import sin, sqrt, pow\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import os\r\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "\r\n",
        "def funkcja(x, y):\r\n",
        "  return sin(sqrt(pow(x, 2) + pow(y, 2)))/sqrt(pow(x, 2) + pow(y, 2))\r\n",
        "\r\n",
        "xs2 = np.arange(-40.0, 40.1, 0.1, dtype = float)\r\n",
        "ys2 = np.arange(-40.0, 40.1, 0.1, dtype = float)\r\n",
        "zs = []\r\n",
        "xy = []\r\n",
        "for x,y in zip(xs2, ys2):\r\n",
        "  zs.append(funkcja(x, y))\r\n",
        "  xy.append([x, y])\r\n",
        "xy = np.asarray(xy, dtype = float)\r\n",
        "zs = np.asarray(zs, dtype = float)\r\n",
        "model2 = tf.keras.Sequential([\r\n",
        "                             keras.layers.Dense(1000, input_shape = [2]),\r\n",
        "                             keras.layers.Dense(1000),\r\n",
        "                             keras.layers.Dense(1000),\r\n",
        "                             keras.layers.Dense(1000),\r\n",
        "                             keras.layers.Dense(1000),\r\n",
        "                             keras.layers.Dense(1)\r\n",
        "                             ])\r\n",
        "model2.compile(optimizer = 'adam', loss = 'mean_squared_error')\r\n",
        "model2.fit(xy, zs, epochs = 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4991.4203\n",
            "Epoch 2/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 79.0620\n",
            "Epoch 3/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.2287\n",
            "Epoch 4/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1385\n",
            "Epoch 5/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0393\n",
            "Epoch 6/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0277\n",
            "Epoch 7/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0357\n",
            "Epoch 8/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0212\n",
            "Epoch 9/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0262\n",
            "Epoch 10/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0354\n",
            "Epoch 11/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0341\n",
            "Epoch 12/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0278\n",
            "Epoch 13/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0272\n",
            "Epoch 14/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0299\n",
            "Epoch 15/500\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0249\n",
            "Epoch 16/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0310\n",
            "Epoch 17/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0223\n",
            "Epoch 18/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0297\n",
            "Epoch 19/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0221\n",
            "Epoch 20/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0222\n",
            "Epoch 21/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0248\n",
            "Epoch 22/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0256\n",
            "Epoch 23/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0229\n",
            "Epoch 24/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0247\n",
            "Epoch 25/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0275\n",
            "Epoch 26/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0338\n",
            "Epoch 27/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0204\n",
            "Epoch 28/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0262\n",
            "Epoch 29/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0327\n",
            "Epoch 30/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0265\n",
            "Epoch 31/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0245\n",
            "Epoch 32/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0279\n",
            "Epoch 33/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0254\n",
            "Epoch 34/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0243\n",
            "Epoch 35/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0319\n",
            "Epoch 36/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0298\n",
            "Epoch 37/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0312\n",
            "Epoch 38/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0313\n",
            "Epoch 39/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0303\n",
            "Epoch 40/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0255\n",
            "Epoch 41/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0178\n",
            "Epoch 42/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0232\n",
            "Epoch 43/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0308\n",
            "Epoch 44/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0307\n",
            "Epoch 45/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0237\n",
            "Epoch 46/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0292\n",
            "Epoch 47/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0304\n",
            "Epoch 48/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0229\n",
            "Epoch 49/500\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0272\n",
            "Epoch 50/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0293\n",
            "Epoch 51/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0293\n",
            "Epoch 52/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0340\n",
            "Epoch 53/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0341\n",
            "Epoch 54/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0289\n",
            "Epoch 55/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0335\n",
            "Epoch 56/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0258\n",
            "Epoch 57/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0239\n",
            "Epoch 58/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0331\n",
            "Epoch 59/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0219\n",
            "Epoch 60/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0223\n",
            "Epoch 61/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0350\n",
            "Epoch 62/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0210\n",
            "Epoch 63/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0297\n",
            "Epoch 64/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0222\n",
            "Epoch 65/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0293\n",
            "Epoch 66/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0208\n",
            "Epoch 67/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0223\n",
            "Epoch 68/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0237\n",
            "Epoch 69/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0333\n",
            "Epoch 70/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0267\n",
            "Epoch 71/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0248\n",
            "Epoch 72/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0253\n",
            "Epoch 73/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0241\n",
            "Epoch 74/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0227\n",
            "Epoch 75/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0278\n",
            "Epoch 76/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0294\n",
            "Epoch 77/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0290\n",
            "Epoch 78/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0248\n",
            "Epoch 79/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0289\n",
            "Epoch 80/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0273\n",
            "Epoch 81/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0256\n",
            "Epoch 82/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0266\n",
            "Epoch 83/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0216\n",
            "Epoch 84/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0335\n",
            "Epoch 85/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0265\n",
            "Epoch 86/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0302\n",
            "Epoch 87/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0222\n",
            "Epoch 88/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0227\n",
            "Epoch 89/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0275\n",
            "Epoch 90/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0344\n",
            "Epoch 91/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0301\n",
            "Epoch 92/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0320\n",
            "Epoch 93/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0268\n",
            "Epoch 94/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0315\n",
            "Epoch 95/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0234\n",
            "Epoch 96/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0287\n",
            "Epoch 97/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0283\n",
            "Epoch 98/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0226\n",
            "Epoch 99/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0385\n",
            "Epoch 100/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0246\n",
            "Epoch 101/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0243\n",
            "Epoch 102/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0268\n",
            "Epoch 103/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0292\n",
            "Epoch 104/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0310\n",
            "Epoch 105/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0296\n",
            "Epoch 106/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0283\n",
            "Epoch 107/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0272\n",
            "Epoch 108/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0288\n",
            "Epoch 109/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0257\n",
            "Epoch 110/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0327\n",
            "Epoch 111/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0229\n",
            "Epoch 112/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0264\n",
            "Epoch 113/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0221\n",
            "Epoch 114/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0302\n",
            "Epoch 115/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0275\n",
            "Epoch 116/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0294\n",
            "Epoch 117/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0252\n",
            "Epoch 118/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0330\n",
            "Epoch 119/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0277\n",
            "Epoch 120/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0226\n",
            "Epoch 121/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0315\n",
            "Epoch 122/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0251\n",
            "Epoch 123/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0291\n",
            "Epoch 124/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0171\n",
            "Epoch 125/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0374\n",
            "Epoch 126/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0364\n",
            "Epoch 127/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0233\n",
            "Epoch 128/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0265\n",
            "Epoch 129/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0201\n",
            "Epoch 130/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0336\n",
            "Epoch 131/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0196\n",
            "Epoch 132/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0277\n",
            "Epoch 133/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0242\n",
            "Epoch 134/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0314\n",
            "Epoch 135/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0260\n",
            "Epoch 136/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0314\n",
            "Epoch 137/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0248\n",
            "Epoch 138/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0321\n",
            "Epoch 139/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0470\n",
            "Epoch 140/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0807\n",
            "Epoch 141/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0398\n",
            "Epoch 142/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0327\n",
            "Epoch 143/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0301\n",
            "Epoch 144/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0222\n",
            "Epoch 145/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0256\n",
            "Epoch 146/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0302\n",
            "Epoch 147/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0311\n",
            "Epoch 148/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0260\n",
            "Epoch 149/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0240\n",
            "Epoch 150/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0266\n",
            "Epoch 151/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0250\n",
            "Epoch 152/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0290\n",
            "Epoch 153/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0239\n",
            "Epoch 154/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0279\n",
            "Epoch 155/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0307\n",
            "Epoch 156/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0338\n",
            "Epoch 157/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0282\n",
            "Epoch 158/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0232\n",
            "Epoch 159/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0271\n",
            "Epoch 160/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0232\n",
            "Epoch 161/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0275\n",
            "Epoch 162/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0253\n",
            "Epoch 163/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0256\n",
            "Epoch 164/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0269\n",
            "Epoch 165/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0298\n",
            "Epoch 166/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0276\n",
            "Epoch 167/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0331\n",
            "Epoch 168/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0256\n",
            "Epoch 169/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0402\n",
            "Epoch 170/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0268\n",
            "Epoch 171/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0299\n",
            "Epoch 172/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0282\n",
            "Epoch 173/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0318\n",
            "Epoch 174/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0215\n",
            "Epoch 175/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0309\n",
            "Epoch 176/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0261\n",
            "Epoch 177/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0325\n",
            "Epoch 178/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0332\n",
            "Epoch 179/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0318\n",
            "Epoch 180/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0285\n",
            "Epoch 181/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0220\n",
            "Epoch 182/500\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0355\n",
            "Epoch 183/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0255\n",
            "Epoch 184/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0240\n",
            "Epoch 185/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0220\n",
            "Epoch 186/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0333\n",
            "Epoch 187/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0269\n",
            "Epoch 188/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0274\n",
            "Epoch 189/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0261\n",
            "Epoch 190/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0221\n",
            "Epoch 191/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0256\n",
            "Epoch 192/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0262\n",
            "Epoch 193/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0277\n",
            "Epoch 194/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0273\n",
            "Epoch 195/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0233\n",
            "Epoch 196/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0344\n",
            "Epoch 197/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0236\n",
            "Epoch 198/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0421\n",
            "Epoch 199/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0322\n",
            "Epoch 200/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0293\n",
            "Epoch 201/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0342\n",
            "Epoch 202/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0252\n",
            "Epoch 203/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0305\n",
            "Epoch 204/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0347\n",
            "Epoch 205/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0271\n",
            "Epoch 206/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0310\n",
            "Epoch 207/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0240\n",
            "Epoch 208/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0245\n",
            "Epoch 209/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0352\n",
            "Epoch 210/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0275\n",
            "Epoch 211/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0278\n",
            "Epoch 212/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0347\n",
            "Epoch 213/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0278\n",
            "Epoch 214/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0315\n",
            "Epoch 215/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0495\n",
            "Epoch 216/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0289\n",
            "Epoch 217/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0273\n",
            "Epoch 218/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0332\n",
            "Epoch 219/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0290\n",
            "Epoch 220/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0247\n",
            "Epoch 221/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0277\n",
            "Epoch 222/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0270\n",
            "Epoch 223/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0216\n",
            "Epoch 224/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0417\n",
            "Epoch 225/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0419\n",
            "Epoch 226/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0248\n",
            "Epoch 227/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0259\n",
            "Epoch 228/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0228\n",
            "Epoch 229/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0317\n",
            "Epoch 230/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0262\n",
            "Epoch 231/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0218\n",
            "Epoch 232/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0300\n",
            "Epoch 233/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0239\n",
            "Epoch 234/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0337\n",
            "Epoch 235/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0297\n",
            "Epoch 236/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0260\n",
            "Epoch 237/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0215\n",
            "Epoch 238/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0263\n",
            "Epoch 239/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0291\n",
            "Epoch 240/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0324\n",
            "Epoch 241/500\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0203\n",
            "Epoch 242/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0264\n",
            "Epoch 243/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0216\n",
            "Epoch 244/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0228\n",
            "Epoch 245/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0328\n",
            "Epoch 246/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0261\n",
            "Epoch 247/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0318\n",
            "Epoch 248/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0337\n",
            "Epoch 249/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0303\n",
            "Epoch 250/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0226\n",
            "Epoch 251/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0222\n",
            "Epoch 252/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0258\n",
            "Epoch 253/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0248\n",
            "Epoch 254/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0233\n",
            "Epoch 255/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0390\n",
            "Epoch 256/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0285\n",
            "Epoch 257/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0274\n",
            "Epoch 258/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0211\n",
            "Epoch 259/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0263\n",
            "Epoch 260/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0271\n",
            "Epoch 261/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0260\n",
            "Epoch 262/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0306\n",
            "Epoch 263/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0280\n",
            "Epoch 264/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0319\n",
            "Epoch 265/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0260\n",
            "Epoch 266/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0302\n",
            "Epoch 267/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0553\n",
            "Epoch 268/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0323\n",
            "Epoch 269/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0251\n",
            "Epoch 270/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0332\n",
            "Epoch 271/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0391\n",
            "Epoch 272/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0262\n",
            "Epoch 273/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0299\n",
            "Epoch 274/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0350\n",
            "Epoch 275/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0222\n",
            "Epoch 276/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0306\n",
            "Epoch 277/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0356\n",
            "Epoch 278/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0270\n",
            "Epoch 279/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0265\n",
            "Epoch 280/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0288\n",
            "Epoch 281/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0298\n",
            "Epoch 282/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0230\n",
            "Epoch 283/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0321\n",
            "Epoch 284/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0334\n",
            "Epoch 285/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0285\n",
            "Epoch 286/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0284\n",
            "Epoch 287/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0295\n",
            "Epoch 288/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0268\n",
            "Epoch 289/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0364\n",
            "Epoch 290/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0287\n",
            "Epoch 291/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0365\n",
            "Epoch 292/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0237\n",
            "Epoch 293/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0310\n",
            "Epoch 294/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0275\n",
            "Epoch 295/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0267\n",
            "Epoch 296/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0319\n",
            "Epoch 297/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0264\n",
            "Epoch 298/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0286\n",
            "Epoch 299/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0342\n",
            "Epoch 300/500\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0241\n",
            "Epoch 301/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0385\n",
            "Epoch 302/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0256\n",
            "Epoch 303/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0344\n",
            "Epoch 304/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0291\n",
            "Epoch 305/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0286\n",
            "Epoch 306/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0276\n",
            "Epoch 307/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0305\n",
            "Epoch 308/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0276\n",
            "Epoch 309/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0254\n",
            "Epoch 310/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0357\n",
            "Epoch 311/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0281\n",
            "Epoch 312/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0277\n",
            "Epoch 313/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0286\n",
            "Epoch 314/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0275\n",
            "Epoch 315/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0254\n",
            "Epoch 316/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0253\n",
            "Epoch 317/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0259\n",
            "Epoch 318/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0309\n",
            "Epoch 319/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0194\n",
            "Epoch 320/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0246\n",
            "Epoch 321/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0259\n",
            "Epoch 322/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0271\n",
            "Epoch 323/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0325\n",
            "Epoch 324/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0270\n",
            "Epoch 325/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0283\n",
            "Epoch 326/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0377\n",
            "Epoch 327/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0282\n",
            "Epoch 328/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0260\n",
            "Epoch 329/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0255\n",
            "Epoch 330/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0253\n",
            "Epoch 331/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0346\n",
            "Epoch 332/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0315\n",
            "Epoch 333/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0250\n",
            "Epoch 334/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0228\n",
            "Epoch 335/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0263\n",
            "Epoch 336/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0274\n",
            "Epoch 337/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0295\n",
            "Epoch 338/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0348\n",
            "Epoch 339/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0291\n",
            "Epoch 340/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0322\n",
            "Epoch 341/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0300\n",
            "Epoch 342/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0281\n",
            "Epoch 343/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0323\n",
            "Epoch 344/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0322\n",
            "Epoch 345/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0308\n",
            "Epoch 346/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0353\n",
            "Epoch 347/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0348\n",
            "Epoch 348/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0278\n",
            "Epoch 349/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0309\n",
            "Epoch 350/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0209\n",
            "Epoch 351/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0658\n",
            "Epoch 352/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0298\n",
            "Epoch 353/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0288\n",
            "Epoch 354/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0325\n",
            "Epoch 355/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0319\n",
            "Epoch 356/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0230\n",
            "Epoch 357/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0258\n",
            "Epoch 358/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0347\n",
            "Epoch 359/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0285\n",
            "Epoch 360/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0207\n",
            "Epoch 361/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0276\n",
            "Epoch 362/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0337\n",
            "Epoch 363/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0302\n",
            "Epoch 364/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0283\n",
            "Epoch 365/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0371\n",
            "Epoch 366/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0338\n",
            "Epoch 367/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0246\n",
            "Epoch 368/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0273\n",
            "Epoch 369/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0338\n",
            "Epoch 370/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0282\n",
            "Epoch 371/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0304\n",
            "Epoch 372/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0253\n",
            "Epoch 373/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0285\n",
            "Epoch 374/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0273\n",
            "Epoch 375/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0264\n",
            "Epoch 376/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0267\n",
            "Epoch 377/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0243\n",
            "Epoch 378/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0367\n",
            "Epoch 379/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0352\n",
            "Epoch 380/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0274\n",
            "Epoch 381/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0274\n",
            "Epoch 382/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0267\n",
            "Epoch 383/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0307\n",
            "Epoch 384/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0286\n",
            "Epoch 385/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0225\n",
            "Epoch 386/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0218\n",
            "Epoch 387/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0231\n",
            "Epoch 388/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0445\n",
            "Epoch 389/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0289\n",
            "Epoch 390/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0288\n",
            "Epoch 391/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0279\n",
            "Epoch 392/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0269\n",
            "Epoch 393/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0363\n",
            "Epoch 394/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0300\n",
            "Epoch 395/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0341\n",
            "Epoch 396/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0258\n",
            "Epoch 397/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0233\n",
            "Epoch 398/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0256\n",
            "Epoch 399/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0307\n",
            "Epoch 400/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0312\n",
            "Epoch 401/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0267\n",
            "Epoch 402/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0354\n",
            "Epoch 403/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0383\n",
            "Epoch 404/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0286\n",
            "Epoch 405/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0240\n",
            "Epoch 406/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0295\n",
            "Epoch 407/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0290\n",
            "Epoch 408/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0257\n",
            "Epoch 409/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0285\n",
            "Epoch 410/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0349\n",
            "Epoch 411/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0258\n",
            "Epoch 412/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0201\n",
            "Epoch 413/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0299\n",
            "Epoch 414/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0222\n",
            "Epoch 415/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0261\n",
            "Epoch 416/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0326\n",
            "Epoch 417/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0417\n",
            "Epoch 418/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0322\n",
            "Epoch 419/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0308\n",
            "Epoch 420/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2781077.6164\n",
            "Epoch 421/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2406421.0411\n",
            "Epoch 422/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 87417.9164\n",
            "Epoch 423/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 3196.5783\n",
            "Epoch 424/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 153.5586\n",
            "Epoch 425/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 48.6349\n",
            "Epoch 426/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 35.9641\n",
            "Epoch 427/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 28.2018\n",
            "Epoch 428/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 23.0105\n",
            "Epoch 429/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 18.4729\n",
            "Epoch 430/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 15.0530\n",
            "Epoch 431/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 12.2089\n",
            "Epoch 432/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 9.9803\n",
            "Epoch 433/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 8.0553\n",
            "Epoch 434/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.5855\n",
            "Epoch 435/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.3584\n",
            "Epoch 436/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.3448\n",
            "Epoch 437/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 3.5329\n",
            "Epoch 438/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.8781\n",
            "Epoch 439/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.3300\n",
            "Epoch 440/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.8641\n",
            "Epoch 441/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.5220\n",
            "Epoch 442/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.2283\n",
            "Epoch 443/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9671\n",
            "Epoch 444/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7891\n",
            "Epoch 445/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6370\n",
            "Epoch 446/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4990\n",
            "Epoch 447/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4068\n",
            "Epoch 448/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3253\n",
            "Epoch 449/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2596\n",
            "Epoch 450/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2093\n",
            "Epoch 451/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1733\n",
            "Epoch 452/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1389\n",
            "Epoch 453/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1140\n",
            "Epoch 454/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0939\n",
            "Epoch 455/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0787\n",
            "Epoch 456/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0652\n",
            "Epoch 457/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0583\n",
            "Epoch 458/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0497\n",
            "Epoch 459/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0472\n",
            "Epoch 460/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0432\n",
            "Epoch 461/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0336\n",
            "Epoch 462/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0324\n",
            "Epoch 463/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0332\n",
            "Epoch 464/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0377\n",
            "Epoch 465/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0358\n",
            "Epoch 466/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0293\n",
            "Epoch 467/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0270\n",
            "Epoch 468/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0300\n",
            "Epoch 469/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0253\n",
            "Epoch 470/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0261\n",
            "Epoch 471/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0334\n",
            "Epoch 472/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0204\n",
            "Epoch 473/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0285\n",
            "Epoch 474/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0207\n",
            "Epoch 475/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0271\n",
            "Epoch 476/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0327\n",
            "Epoch 477/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0236\n",
            "Epoch 478/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0299\n",
            "Epoch 479/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0233\n",
            "Epoch 480/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0199\n",
            "Epoch 481/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0271\n",
            "Epoch 482/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0328\n",
            "Epoch 483/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0268\n",
            "Epoch 484/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0317\n",
            "Epoch 485/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0320\n",
            "Epoch 486/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0252\n",
            "Epoch 487/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0261\n",
            "Epoch 488/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0206\n",
            "Epoch 489/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0284\n",
            "Epoch 490/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0282\n",
            "Epoch 491/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0201\n",
            "Epoch 492/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0237\n",
            "Epoch 493/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0259\n",
            "Epoch 494/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0238\n",
            "Epoch 495/500\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0283\n",
            "Epoch 496/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0264\n",
            "Epoch 497/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0270\n",
            "Epoch 498/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0223\n",
            "Epoch 499/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0266\n",
            "Epoch 500/500\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9136723278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e--JsT1xMfAh"
      },
      "source": [
        "Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX4geFRfMg2j",
        "outputId": "85d7ad86-042f-4e83-d2b4-6d2b5e1128f8"
      },
      "source": [
        "x = input(\"Proszę podać x: \")\r\n",
        "y = input(\"Proszę podać y: \")\r\n",
        "print(\"Wynik dla wyznaczonego x i y wynosi:\", model2.predict([[float(x), float(y)]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proszę podać x: 5\n",
            "Proszę podać y: 5\n",
            "Wynik dla wyznaczonego x i y wynosi: [[0.02731668]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSC2PT-Am7dK"
      },
      "source": [
        "#Zadanie 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofeL_UCmqa8R"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from keras.utils import np_utils\r\n",
        "\r\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\r\n",
        "\r\n",
        "\r\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvNgHQ4IwO8b"
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\r\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\r\n",
        "\r\n",
        "train_images = train_images / 255.0\r\n",
        "test_images = test_images / 255.0\r\n",
        "\r\n",
        "train_labels = np_utils.to_categorical(train_labels, 10)\r\n",
        "test_labels = np_utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrR1aVnzwcry",
        "outputId": "aa3c2527-f612-4879-af56-9e988d25c35d"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(28,28,1),padding='same'),\r\n",
        "    tf.keras.layers.BatchNormalization(),\r\n",
        "    tf.keras.layers.Dropout(0.2),\r\n",
        "    tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same'),\r\n",
        "    tf.keras.layers.Dropout(0.2),\r\n",
        "    tf.keras.layers.Conv2D(24, kernel_size=3, activation='relu',padding='same'),\r\n",
        "    tf.keras.layers.Dropout(0.2),\r\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu',padding='same'),\r\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\r\n",
        "    tf.keras.layers.Dropout(0.2),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(128, activation = 'relu'),\r\n",
        "    tf.keras.layers.Dropout(0.3),\r\n",
        "    tf.keras.layers.Dense(10, activation = 'softmax')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size = 128, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 8s 16ms/step - loss: 0.8444 - accuracy: 0.6919\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.3699 - accuracy: 0.8667\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.3062 - accuracy: 0.8872\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.2701 - accuracy: 0.9007\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.2445 - accuracy: 0.9091\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.2132 - accuracy: 0.9210\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.1955 - accuracy: 0.9285\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.1785 - accuracy: 0.9339\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.1667 - accuracy: 0.9374\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.1516 - accuracy: 0.9425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f914048e208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqQtj__lz-r6"
      },
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "w8v1dlxBIC9L",
        "outputId": "f9fbe8a1-e7e0-447e-e210-0d7f554d5784"
      },
      "source": [
        "names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n",
        "\r\n",
        "height = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "height2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "\r\n",
        "for prediction, label in zip(predictions, test_labels):\r\n",
        "  height[np.argmax(prediction)] += 1\r\n",
        "  height2[np.argmax(label)] += 1\r\n",
        "\r\n",
        "fig, axs = plt.subplots(2, figsize = (18, 5))\r\n",
        "axs[0].bar(names, height)\r\n",
        "axs[1].bar(names, height2)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}